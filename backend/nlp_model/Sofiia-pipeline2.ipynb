{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9bf64c1-db68-4bab-8a9c-e7d9288b552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nataliasurzhak/tf-env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db127e17-de0a-4f13-bbc7-c7b845426a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12315d190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Necessary imports and setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from pathlib import Path\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff9a447-90a1-4ae9-8f27-6b763ff8df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data loading - read only the necessary columns from downloaded CSV files,\n",
    "\n",
    "ARCHIVE_DIR = Path(\"~/Desktop/SentiStock/archive\").expanduser()\n",
    "\n",
    "djia_file   = ARCHIVE_DIR / \"djia_news copy.csv\"\n",
    "nasdaq_file = ARCHIVE_DIR / \"nasdaq.csv\"\n",
    "\n",
    "df_djia   = pd.read_csv(djia_file,   usecols=[\"Ticker\", \"Headline\"])\n",
    "df_nasdaq = pd.read_csv(nasdaq_file, usecols=[\"Ticker\", \"Headline\"])\n",
    "\n",
    "df_djia[\"Source\"]   = \"DJIA\"\n",
    "df_nasdaq[\"Source\"] = \"NASDAQ\"\n",
    "\n",
    "df_all = pd.concat([df_djia, df_nasdaq], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d1d915-6e35-4a74-be72-17cf51651ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJIA news sample:\n",
      "DJIA news sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Employer who stole nearly $3M in wages from 15...</td>\n",
       "      <td>DJIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Huge new Facebook data leak exposed intimate d...</td>\n",
       "      <td>DJIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMM</td>\n",
       "      <td>A campaign has accelerated to turn a disused r...</td>\n",
       "      <td>DJIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Google launches global human trafficking helpl...</td>\n",
       "      <td>DJIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Over 3m Saudi Women Don’t Have ID Cards; Saudi...</td>\n",
       "      <td>DJIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker                                           Headline Source\n",
       "0    MMM  Employer who stole nearly $3M in wages from 15...   DJIA\n",
       "1    MMM  Huge new Facebook data leak exposed intimate d...   DJIA\n",
       "2    MMM  A campaign has accelerated to turn a disused r...   DJIA\n",
       "3    MMM  Google launches global human trafficking helpl...   DJIA\n",
       "4    MMM  Over 3m Saudi Women Don’t Have ID Cards; Saudi...   DJIA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASDAQ news sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>@TotesTravel : Airline shares tumble as New Yo...</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>@TotesTravel : American United call off Hong K...</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>@TotesTravel : U.S. airline stocks hit highest...</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>@TotesTravel : American Airlines reaches deal ...</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>@TotesTravel : US airlines Treasury Department...</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker                                           Headline  Source\n",
       "0      A  @TotesTravel : Airline shares tumble as New Yo...  NASDAQ\n",
       "1      A  @TotesTravel : American United call off Hong K...  NASDAQ\n",
       "2      A  @TotesTravel : U.S. airline stocks hit highest...  NASDAQ\n",
       "3      A  @TotesTravel : American Airlines reaches deal ...  NASDAQ\n",
       "4      A  @TotesTravel : US airlines Treasury Department...  NASDAQ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Inspect the loaded data\n",
    "print(\"DJIA news sample:\")\n",
    "print(\"DJIA news sample:\")\n",
    "display(df_djia.head())\n",
    "\n",
    "print(\"NASDAQ news sample:\")\n",
    "display(df_nasdaq.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0af64da-e8e9-4f6c-addf-607e7f42a5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Industry Cites 3M experiment that exposed canc...</td>\n",
       "      <td>DJIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Canadian PM Justin Trudeau has said he will no...</td>\n",
       "      <td>DJIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>AMGN</td>\n",
       "      <td>Amgen exits neuroscience R&amp;amp;D as pharma pul...</td>\n",
       "      <td>DJIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>AMGN</td>\n",
       "      <td>From Amgen to Gilead drugmakers are sitting on...</td>\n",
       "      <td>DJIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>France To Take Legal Action Against Facebook G...</td>\n",
       "      <td>DJIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker                                           Headline Source\n",
       "48     MMM  Industry Cites 3M experiment that exposed canc...   DJIA\n",
       "75     MMM  Canadian PM Justin Trudeau has said he will no...   DJIA\n",
       "181   AMGN  Amgen exits neuroscience R&amp;D as pharma pul...   DJIA\n",
       "187   AMGN  From Amgen to Gilead drugmakers are sitting on...   DJIA\n",
       "229   AAPL  France To Take Legal Action Against Facebook G...   DJIA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Goal: Filter headlines to only those mentioning healthcare-related terms\n",
    "hc_terms = [\n",
    "    \"healthcare\", \"patient\", \"medicine\", \"hospital\", \"clinic\",\n",
    "    \"doctor\", \"nurse\", \"pharma\", \"vaccine\", \"treatment\"\n",
    "]\n",
    "pattern = \"|\".join(hc_terms)\n",
    "\n",
    "df_hc = df_all[df_all[\"Headline\"].str.lower().str.contains(pattern)].copy()\n",
    "\n",
    "display(df_hc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d77fc8-73ca-4653-995a-9dcea92130f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████████████████████████████| 21/21 [00:13<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 5. Load tokenizer and model manually (instead of pipeline)\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 6. Tokenize texts and build PyTorch Dataset\n",
    "class FinBERTDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len=128):\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.encodings[\"input_ids\"].size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: val[idx] for key, val in self.encodings.items()\n",
    "        }\n",
    "\n",
    "texts = df_hc[\"Headline\"].tolist()\n",
    "dataset = FinBERTDataset(texts, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "# 6b. Predict sentiment logits and apply softmax\n",
    "all_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader, desc=\"Scoring\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        for p in probs:\n",
    "            all_scores.append([\n",
    "                {\"label\": \"NEGATIVE\", \"score\": p[0].item()},\n",
    "                {\"label\": \"NEUTRAL\",  \"score\": p[1].item()},\n",
    "                {\"label\": \"POSITIVE\", \"score\": p[2].item()},\n",
    "            ])\n",
    "\n",
    "def to_scale_1_10(scores):\n",
    "    \"\"\"\n",
    "    Convert FinBERT output scores into a [1,10] scale:\n",
    "    - NEGATIVE → weight −1\n",
    "    - NEUTRAL  → weight  0\n",
    "    - POSITIVE → weight +1\n",
    "    Then map linearly from [-1,1] to [1,10].\n",
    "    \"\"\"\n",
    "    label2score = {item[\"label\"].upper(): item[\"score\"] for item in scores}\n",
    "    neg = label2score.get(\"NEGATIVE\", 0.0)\n",
    "    pos = label2score.get(\"POSITIVE\", 0.0)\n",
    "    sentiment = pos - neg\n",
    "    return float((sentiment + 1) * 4.5 + 1)\n",
    "    \n",
    "df_hc[\"Sentiment_1_10\"] = [to_scale_1_10(s) for s in all_scores]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf54d3c-de2d-4693-a34d-f0b9f647aaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved healthcare sentiment data to /Users/nataliasurzhak/Desktop/SentiStock/archive/healthcare_sentiment2.csv\n"
     ]
    }
   ],
   "source": [
    "# 7. Save the healthcare-only sentiment scores to CSV\n",
    "output_file = ARCHIVE_DIR / \"healthcare_sentiment2.csv\"\n",
    "df_hc.to_csv(output_file, index=False)\n",
    "print(f\"Saved healthcare sentiment data to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c81717-6ea8-4551-b9cc-6e27c303bcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
