{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d8a389-7ab1-4b54-8237-3172251c8d85",
   "metadata": {},
   "source": [
    "## Tech & Engineering - Raniya\n",
    "Follow along the code to do the preliminary data analysis!\\\n",
    "**Please refer to the [meeting notes here](https://docs.google.com/document/d/1tnDnYfO5m5GQz5Fm7_TbpzHN9bG3RmvqpgvL4TyOevI/edit?usp=sharing) to get familiar with all the column names and the values associated with them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c32d113-8725-441e-b9bc-ba38ebd18094",
   "metadata": {},
   "source": [
    "### Step 1: Install the necessary libraries for our data collection.\n",
    "[yfinance](https://python-yahoofinance.readthedocs.io/en/latest/): used to fetch historical stock data (price, volume, etc.) from Yahoo Finance for our assigned sectors.\\\n",
    "[ta](https://technical-analysis-library-in-python.readthedocs.io/en/latest/): used to calculate technical indicators from the price data we get with yfinance. These indicators help our model understand:\n",
    "- Trends (e.g., SMA, EMA, MACD)\n",
    "- Momentum (e.g., RSI)\n",
    "- Volatility (e.g., ATR, Bollinger Bands)\n",
    "- Volume pressure (e.g., OBV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18cb2a96-d376-475c-93a3-446637ca0083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (0.2.55)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from yfinance) (2.2.4)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Collecting ta\n",
      "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from ta) (2.2.4)\n",
      "Requirement already satisfied: pandas in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from ta) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from pandas->ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from pandas->ta) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from pandas->ta) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/raniyakhan/anaconda3/envs/cleanenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\n",
      "Building wheels for collected packages: ta\n",
      "  Building wheel for ta (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=6a8376ff424c5ec94282e8da8d5ab2735315f10e58d0dc9093ef702b80b51f2b\n",
      "  Stored in directory: /Users/raniyakhan/Library/Caches/pip/wheels/5f/67/4f/8a9f252836e053e532c6587a3230bc72a4deb16b03a829610b\n",
      "Successfully built ta\n",
      "Installing collected packages: ta\n",
      "Successfully installed ta-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance\n",
    "!pip install ta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf2f0c-04e5-45e9-9d67-bc5fc21db744",
   "metadata": {},
   "source": [
    "### Step 2: Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7738a01c-16fa-4653-9e4d-226731c380f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "import ta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc3f82-608b-45f7-a697-9f18fb059ce1",
   "metadata": {},
   "source": [
    "### Step 3: Collect Preliminary Stock Data Using `yfinance`\n",
    "\n",
    "In this step, you will collect **5 years of historical daily stock data** for your assigned sector using the `yfinance` library.\n",
    "\n",
    "**What this code does:**\n",
    "- Loops through a list of stock tickers.\n",
    "- Uses `yfinance` to download daily data for each stock over a 5-year period.\n",
    "- Waits 3 seconds between requests to avoid hitting API limits.\n",
    "- Cleans and formats the data: resets the index and adds a \"Ticker\" column.\n",
    "- Stores all the data in one master DataFrame called `price_df`.\n",
    "\n",
    "**What you need to do:**\n",
    "- Replace the `tickers` list with the stocks **assigned to your sector**.\n",
    "- You can find your list of stocks by referring to the excel file we created earlier [here](https://docs.google.com/spreadsheets/d/19n8ye_mwPM6QVbFJjG4eVUfiqUiGMQ-MujnMY_zMUs8/edit?usp=sharing).\n",
    "- Run the code block to create your `price_df`, which you will later use for feature engineering.\n",
    "\n",
    "If no data is found or an error occurs for a ticker, it will be skipped and reported in the output.\\\n",
    "\n",
    "*If you are running into errors with `yfinance` and hitting api limits, please wait a few hours and try running the code again. Please avoing running the cell multiple times to not run into this issue!*\n",
    "\n",
    "Below is the code you should run (after customizing your ticker list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4b991d-6ccb-4994-a28c-72109f4e331f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL added\n",
      "MSFT added\n",
      "GOOGL added\n",
      "AMZN added\n",
      "NVDA added\n",
      "META added\n",
      "TSLA added\n",
      "TSM added\n",
      "AVGO added\n",
      "ORCL added\n",
      "CSCO added\n",
      "INTC added\n",
      "ADBE added\n",
      "CRM added\n",
      "IBM added\n",
      "TXN added\n",
      "ASML added\n",
      "QCOM added\n",
      "HON added\n",
      "SIEGY added\n",
      "SEZL added\n",
      "IDCC added\n",
      "AGYS added\n",
      "BOX added\n",
      "ZETA added\n",
      "YOU added\n",
      "                       Date Ticker       Open       High        Low  \\\n",
      "0 2020-04-06 00:00:00-04:00   AAPL  60.888178  63.851287  60.519308   \n",
      "1 2020-04-07 00:00:00-04:00   AAPL  65.717481  65.935898  62.853871   \n",
      "2 2020-04-08 00:00:00-04:00   AAPL  63.761500  64.885106  63.395060   \n",
      "3 2020-04-09 00:00:00-04:00   AAPL  65.207845  65.540314  64.237129   \n",
      "4 2020-04-13 00:00:00-04:00   AAPL  65.113192  66.421235  64.511346   \n",
      "\n",
      "       Close     Volume  \n",
      "0  63.695976  201820400  \n",
      "1  62.958221  202887200  \n",
      "2  64.569626  168895200  \n",
      "3  65.035538  161834800  \n",
      "4  66.312027  131022800  \n"
     ]
    }
   ],
   "source": [
    "# Refer back to the csv file to find the stocks you selected, and replace these tickers with your own.\n",
    "tickers = [\n",
    "    \"AAPL\",\"MSFT\",\"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\", \"TSM\",\"AVGO\", \"ORCL\", \"CSCO\", \"INTC\", \"ADBE\",\n",
    "\"CRM\",\n",
    "\"IBM\",\n",
    "\"TXN\",\n",
    "\"ASML\",\n",
    "\"QCOM\",\n",
    "\"HON\",\n",
    "\"SIEGY\",\n",
    "\"SEZL\",\n",
    "\"IDCC\",\n",
    "\"AGYS\",\n",
    "\"BOX\",\n",
    "\"ZETA\",\n",
    "\"YOU\"\n",
    "]\n",
    "\n",
    "#CODE BELOW DOES NOT NEED TO BE CHANGED\n",
    "# List to hold all data\n",
    "all_data = []\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        df = yf.Ticker(ticker).history(period=\"5y\", interval=\"1d\")\n",
    "        time.sleep(3) # wait in between requests to avoid request limits\n",
    "        if df.empty:\n",
    "            print(f\"No data for {ticker}\")\n",
    "            continue\n",
    "\n",
    "        df = df.reset_index()  # Convert index to Date column\n",
    "        df[\"Ticker\"] = ticker  # Add ticker column\n",
    "        all_data.append(df[[\"Date\", \"Ticker\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]])\n",
    "        print(f\"{ticker} added\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {ticker}: {e}\")\n",
    "\n",
    "# Concatenate all into one DataFrame\n",
    "price_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Preview the result\n",
    "print(price_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9213945-d76c-4847-8f93-db63d6b0f92e",
   "metadata": {},
   "source": [
    "### Step 4: Generate Price-Based and Technical Indicators\n",
    "\n",
    "Now that you have your stock data, it’s time to create additional features that help the model understand market trends, volatility, and momentum.\n",
    "\n",
    "**What this code does:**\n",
    "- Calculates **daily returns** and **VWAP** (volume-weighted average price).\n",
    "- Adds several **technical indicators** like:\n",
    "  - Simple and Exponential Moving Averages (SMA, EMA)\n",
    "  - Relative Strength Index (RSI)\n",
    "  - MACD and Signal Line\n",
    "  - Bollinger Bands (Upper and Lower)\n",
    "  - Average True Range (ATR)\n",
    "  - On-Balance Volume (OBV)\n",
    "- Groups the data by ticker to apply indicator calculations correctly.\n",
    "- Combines everything into a single DataFrame with all features.\n",
    "\n",
    "**What you need to do:**\n",
    "- You **do not need to modify anything** in this code block **except one thing**:\n",
    "  - In the **last line**, rename the CSV file to reflect your assigned sector name:\n",
    "    ```python\n",
    "    tech_df.to_csv(\"your_sector_name_data_with_indicators.csv\", index=False)\n",
    "    ```\n",
    "\n",
    "Once this is done, you’ll have a feature-rich dataset ready for modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aac97058-fa1a-4fe8-bbe0-1556d8519c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df = price_df.copy()\n",
    "\n",
    "# --- Price-based indicators ---\n",
    "tech_df['Daily Return'] = tech_df.groupby(\"Ticker\")['Close'].pct_change(fill_method=None)\n",
    "tech_df['Typical Price'] = (tech_df['High'] + tech_df['Low'] + tech_df['Close']) / 3\n",
    "tech_df['VWAP'] = (tech_df['Typical Price'] * tech_df['Volume']).groupby(tech_df['Ticker']).cumsum() / tech_df['Volume'].groupby(tech_df['Ticker']).cumsum()\n",
    "\n",
    "# --- Technical indicators ---\n",
    "grouped = tech_df.groupby(\"Ticker\", group_keys=False)\n",
    "tech_df['SMA_20'] = grouped['Close'].apply(lambda x: x.rolling(window=20).mean())\n",
    "tech_df['EMA_20'] = grouped['Close'].apply(lambda x: x.ewm(span=20, adjust=False).mean())\n",
    "tech_df['RSI_14'] = grouped['Close'].apply(lambda x: ta.momentum.RSIIndicator(close=x, window=14).rsi())\n",
    "tech_df['MACD'] = grouped['Close'].apply(lambda x: ta.trend.MACD(close=x).macd())\n",
    "tech_df['MACD_Signal'] = grouped['Close'].apply(lambda x: ta.trend.MACD(close=x).macd_signal())\n",
    "tech_df['BB_Upper'] = grouped['Close'].apply(lambda x: ta.volatility.BollingerBands(close=x, window=20).bollinger_hband())\n",
    "tech_df['BB_Lower'] = grouped['Close'].apply(lambda x: ta.volatility.BollingerBands(close=x, window=20).bollinger_lband())\n",
    "# Create empty columns\n",
    "tech_df['ATR'] = None\n",
    "tech_df['OBV'] = None\n",
    "\n",
    "# Loop through each group (ticker) and calculate indicators\n",
    "result_frames = []\n",
    "\n",
    "for ticker, group in tech_df.groupby(\"Ticker\"):\n",
    "    group = group.copy()\n",
    "    group.sort_values('Date', inplace=True)\n",
    "\n",
    "    # ATR\n",
    "    atr = ta.volatility.AverageTrueRange(\n",
    "        high=group['High'],\n",
    "        low=group['Low'],\n",
    "        close=group['Close']\n",
    "    ).average_true_range()\n",
    "    group['ATR'] = atr\n",
    "\n",
    "    # OBV\n",
    "    obv = ta.volume.OnBalanceVolumeIndicator(\n",
    "        close=group['Close'],\n",
    "        volume=group['Volume']\n",
    "    ).on_balance_volume()\n",
    "    group['OBV'] = obv\n",
    "\n",
    "    result_frames.append(group)\n",
    "\n",
    "# Combine the updated groups back together\n",
    "tech_df = pd.concat(result_frames, ignore_index=True)\n",
    "\n",
    "# Save to CSV, rename it to correspond to your sector. Please replace \"sector\" with your corresponding sector.\n",
    "tech_df.to_csv(\"tech_engineering_data_with_indicators.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cce63cf-1e21-488c-b129-bfa9d88fedcd",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7940aa-b291-4ace-85dd-258b2392f1df",
   "metadata": {},
   "source": [
    "Load the csv you just created, and give it a name. Replace the csv name (what is in quoets \"\"), with the csv you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea651a2-c408-4e26-b522-3bd715627c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "techeng_df = pd.read_csv(\"tech_engineering_data_with_indicators.csv\")\n",
    "techeng_df.head() #shows first 5 rows of data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437d0a9-46b3-4fa1-89ff-2afd2bbe370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d87e5-5ed7-4889-a5de-3f3adee930fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import numpy as np\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot settings for nicer visuals\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e462eea-b4c9-4368-bd9e-666024c908b7",
   "metadata": {},
   "source": [
    "### EDA Guidelines\n",
    "\n",
    "Follow these steps to explore and understand your dataset before modeling. This will help uncover patterns, identify issues, and engineer features that improve performance.\n",
    "\n",
    "**Resources (Videos):**\n",
    "- [Learn EDA - Playlist](https://www.youtube.com/watch?v=78ut-S-QOEQ&list=PLe9UEU4oeAuV7RtCbL76hca5ELO_IELk4&ab_channel=MarkKeith)\n",
    "- [Complete Exploratory Data Analysis And Feature Engineering In 3 Hours| Krish Naik](https://youtu.be/fHFOANOHwh8?si=1SRsxlRJpOlUGMhI)\n",
    "- [How to Do Data Exploration (step-by-step tutorial on real-life dataset)](https://youtu.be/OY4eQrekQvs?si=i1QzaMrCFQmxg1uJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f30f34-865e-4fdf-a22f-4f446e96ba9c",
   "metadata": {},
   "source": [
    "#### 1) Get Rid of Any Null Values If You Have Any\n",
    "\n",
    "- First, check for missing (`NaN`) values across all columns.\n",
    "- If there are only a few missing entries, drop them.\n",
    "- **Resource**: [A Guide to Handling Missing values in Python](https://www.kaggle.com/code/parulpandey/a-guide-to-handling-missing-values-in-python)\n",
    "\n",
    "```python\n",
    "# Check for null values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Drop rows with any nulls (simple but aggressive)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d0686f-f8da-4849-825d-7698ac59815d",
   "metadata": {},
   "source": [
    "#### 2) Inspect Your Overall Cleaned Dataset Using Summary Statistics\n",
    "- Use `.info()` and `.describe()` to understand the shape, datatypes, and distributions of the dataset.\n",
    "- This gives a high-level snapshot of numeric features and potential outliers or irregularities.\n",
    "- **Resource:**: [An Introduction To Summary Statistics In Python (With Code Examples)](https://zerotomastery.io/blog/summary-statistics-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa37b4-88ef-4d33-8b4d-530314134ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2a8fbc1-4435-4127-8158-a805d5e9fa3a",
   "metadata": {},
   "source": [
    "#### 3) Create Plots to Explore Distributions\n",
    "Plot histograms and KDE plots to check how features like RSI, MACD, and Volume, etc. are distributed. This helps you spot skewness, spikes, and potential transformations.\n",
    "**Resources**: \n",
    "- [Seaborn Kdeplot - A Comprehensive Guide](https://www.digitalocean.com/community/tutorials/seaborn-kdeplot)\n",
    "- [Python Histogram Plotting: NumPy, Matplotlib, pandas & Seaborn](https://realpython.com/python-histograms/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee3853-2eb5-4910-bf58-e6c8fee2c071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6ef60cc-6fbe-4e8c-9480-0b0add1cc51e",
   "metadata": {},
   "source": [
    "#### 4) Generate a Correlation Heatmap to Spot Redundant Features\n",
    "Highly correlated features can be redundant and may hurt certain models. Use a heatmap to visually inspect correlation between numerical features.\n",
    "- **Resource**: [5 Minute EDA: Correlation Heatmap](https://medium.com/5-minute-eda/5-minute-eda-correlation-heatmap-b57bbb7bae14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dac2d0-3d2b-4601-ac5b-de73eb4988c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b9c0e58-b403-4b4d-87da-f00369ac62f4",
   "metadata": {},
   "source": [
    "#### 5) Check the Relationship Between Features and the Target\n",
    "Explore how technical indicators relate to the target (next day’s close). Use scatter plots or group-by summaries to spot patterns.\n",
    "- **Resource**: [Scatter plot with a grouping variable with Pandas](https://python-graph-gallery.com/537-scatter-plots-grouped-by-color-with-pandas/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d848ce6-eb4a-4754-b1a0-d6a0051d0569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4043f1b2-0627-44a5-acb5-2bf273e2edd5",
   "metadata": {},
   "source": [
    "#### 6) Use Boxplots to Detect Outliers\n",
    "- Boxplots are a great way to spot extreme values or outliers in numeric features. \n",
    "- Outliers can influence your model heavily — decide whether to keep, remove, or transform them.\n",
    "- **Resource**: [How to detect outliers using IQR and Boxplots?](https://www.machinelearningplus.com/machine-learning/how-to-detect-outliers-using-iqr-and-boxplots/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6484a03c-467e-415c-bdd8-61a71393e925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6badfc54-fd5d-47e3-b4ff-456fd6b5db7a",
   "metadata": {},
   "source": [
    "#### 7) Investigate Patterns Over Time or Between Groups (Sector, Ticker, etc.)\n",
    "- Use time-based plots to see if the target or indicators change by day of the week or over time.\n",
    "- Grouped boxplots can help reveal differences between companies or sectors.\n",
    "- **Resource**: [Python Plotting for Exploratory Data Analysis](https://pythonplot.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef3ddf-3976-4ecf-9410-430af4149fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6745c34b-4d3c-4696-bdff-967476560810",
   "metadata": {},
   "source": [
    "#### 8) Brainstorm & Engineer New Features Based on Your Insights\n",
    "- Consider creating features like price range, volatility, lagged prices, or differences from moving averages.\n",
    "- These can help capture patterns not directly visible in raw features.\n",
    "- **Resource**: [A Reference Guide to Feature Engineering](https://www.kaggle.com/code/prashant111/a-reference-guide-to-feature-engineering-methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd70d62b-9622-434f-af82-39ba980ca277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
